{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn 특징 추출\n",
    "\n",
    "* CountVectorizer\n",
    "* TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer<br><br>\n",
    "\n",
    "전체 데이터에서 토큰을 생성하고, 각 단어별 index를 만들어 dict로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer.fit(text_data) #자동으로 단어 사전 생성 \n",
    "print(count_vectorizer.vocabulary_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"나는 배가 배가 고프다 \"]  \n",
    "print(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer<br>\n",
    "TF (Term Frequency) 란 특정 단어가 하나의 데이터 안에서 등장하는 횟수<br><br>\n",
    "DF(Document Frequency) 란 특정 단어가 하나의 데이터 안에서 등장하는 횟수<br><br>\n",
    "IDF(Inverse Document Frequency ) DF 의 역수 : 특정 단어가 다른 데이터에 등장 하지 않을 수로 값이 커짐<br><br>\n",
    "TFI DF 란 TF 와 IDF 값을 곱해서 사용 어떤 단어가 해당 문서에 자주 등장하지만 다른 문서에는 많이 없는 단어 일수록 높은 값 조사나 지시 대명사처럼 자주 등장하는 단어는 TF 값은 크지만 IDF 값은 작아지므로 CounterVectorizer 의 단점을 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text_data) #자동으로 단어 사전 생성 \n",
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t0.5552826649411127\n",
      "  (0, 7)\t0.43779123108611473\n",
      "  (0, 4)\t0.5552826649411127\n",
      "  (0, 1)\t0.43779123108611473\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[3]] # ['점심 먹고 공부 해야지']\n",
    "print(tfidf_vectorizer.transform(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t0.5773502691896257\n",
      "  (0, 2)\t0.5773502691896257\n",
      "  (0, 0)\t0.5773502691896257\n",
      "  (1, 7)\t0.5264054336099155\n",
      "  (1, 5)\t0.6676785446095399\n",
      "  (1, 3)\t0.5264054336099155\n",
      "  (2, 8)\t0.6676785446095399\n",
      "  (2, 3)\t0.5264054336099155\n",
      "  (2, 1)\t0.5264054336099155\n",
      "  (3, 9)\t0.5552826649411127\n",
      "  (3, 7)\t0.43779123108611473\n",
      "  (3, 4)\t0.5552826649411127\n",
      "  (3, 1)\t0.43779123108611473\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.transform(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
